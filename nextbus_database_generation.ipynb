{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all purpose\n",
    "import datetime, geoplotlib, re\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# for talking to SQL databases\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "# json and XML parsing\n",
    "import json\n",
    "from pprint import pprint\n",
    "from urllib2 import urlopen\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "# for making maps\n",
    "import geoplotlib\n",
    "from geoplotlib.utils import BoundingBox\n",
    "from IPython.display import Image\n",
    "\n",
    "# all purpose data analysis and plotting\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define this function for computing distances in meters from (lat,lon) coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will need this function to compute the distance between two (lat,lon) points, in meters\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    meters = 6367 * c * 1000\n",
    "    return meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from PostgreSQL database I've built with API calls\n",
    "### Initial exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write generate_route_pair function \n",
    "Pulls data from SQL database, computes entry in final database, which is pairs subsequent buses on the same route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to connect to the PostgresSQL database that I am reading the NextBus Muni data into, which is called 'sf_muni_arrivals' in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbname = 'sf_muni_arrivals'\n",
    "username = 'dstone'\n",
    "table = 'nextbus_write_2016_01_15'\n",
    "\n",
    "# Open up an engine, that we will use to create the database if it doesn't exist\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following command loads the ENTIRE SQL database from above into a pandas dataframe. In the future, I will want to sort the data first with SQL commands, then load it into a pandas dataframe. I can do that with the commented out text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If I want to filter the data first:\n",
    "# connect:\n",
    "db_con = None\n",
    "db_con = psycopg2.connect(database = dbname, user = username)\n",
    "# the table name is 'nextbus':\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM {table};\n",
    "\"\"\".format(table=table)\n",
    "nbdata = pd.read_sql_query(sql_query,db_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbdata.drop(nbdata.index[0], inplace=True)\n",
    "nbdata.drop(nbdata.index[-1], inplace=True)\n",
    "#nbdata.columns = ['vehicle','received_time','gps_time','gpsfix','speed','heading','route','trip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "routeslist = pd.unique(nbdata['route'].ravel())\n",
    "list_of_muni_routes = pd.DataFrame(data=routeslist, index = range(len(routeslist)), columns=['route'])\n",
    "\n",
    "# Clean up a bit\n",
    "list_of_muni_routes = list_of_muni_routes[(list_of_muni_routes.route.isnull() == False) & (list_of_muni_routes.route != 'Inspectors') & (list_of_muni_routes.route != 'Training')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write the function here. Idea: run over 'list_of_muni_routes', for each route, create the pairs (there will be many) of entries (this is done in various sections of code below), write them to a SQL database, db and table of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function generates a table of pairs for a given route\n",
    "# assume a database connection is already established\n",
    "def generate_route_pairs(route, database_connection, table):\n",
    "    sql_query = '''SELECT * FROM {table} WHERE route = {route};'''.format(table=table,route=route)\n",
    "    df_route = pd.read_sql_query(sql_query, database_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Some clean up of this data: remove all whitespaces in file, drop first row, rename columns so they are free of whitespaces, get GPS coordinates separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we redefine the lat, lon coordinates into separate columns, and drop the old 'gpsfix' column. Finally, we reinterpret the times and coarse-grain to the minute (LATER: do to the half-minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: merge the two tables with only their lat longs (time stamps included in index), compute distance on that table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist1 = pd.merge(left=trip_0[['lat','lon','time']],right=trip_1[['lat','lon','time']],on='time').apply(lambda row: haversine(row['lat_x'],row['lon_x'],row['lat_y'],row['lon_y']), axis=1)\n",
    "dist2 = pd.merge(left=trip_1[['lat','lon','time']],right=trip_2[['lat','lon','time']],on='time').apply(lambda row: haversine(row['lat_x'],row['lon_x'],row['lat_y'],row['lon_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coords_dict = {}\n",
    "for i in range(len(trips_in_order_30)):\n",
    "    my_key = \"trip_\"+str(i)\n",
    "    if my_key not in coords_dict:\n",
    "        coords_dict[my_key] = 0\n",
    "\n",
    "for i in range(len(trips_in_order_30)):\n",
    "    trip_temp = 'trip_'+str(i)\n",
    "    tmp_vehicles = pd.unique(route30[(route30.trip == trips_in_order_30[i])].vehicle.ravel())\n",
    "    coords_dict[trip_temp] = route30[(route30.trip == trips_in_order_30[i]) & (route30.vehicle == tmp_vehicles[0])][['lat','lon','time']]\n",
    "    coords_dict[trip_temp].drop_duplicates(subset='time', inplace=True)\n",
    "    coords_dict[trip_temp].index = coords_dict[trip_temp].time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a dataframe that has time stamps and distances, by computing successive differences between each pair of trips, then appending (with pd.concat) each collection of (time, distance) of each pair of trips to the empty dist dataframe, which will end up containing all distances from pairs of trips on the route 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# substract one from length of trip_in_order_30 so that final pair of trips doesn't go outside index range\n",
    "#for i in range(len(trips_in_order_30)-1):\n",
    "for i in range(len(trips_in_order_30)-1):\n",
    "    trip_now = 'trip_'+str(i)\n",
    "    trip_next = 'trip_'+str(i+1)\n",
    "    #print 'Merging {trip1} and {trip2}'.format(trip1=trip_now,trip2=trip_next)\n",
    "    tmp = pd.merge(left=coords_dict[trip_now],right=coords_dict[trip_next],on='time')\n",
    "    if tmp.shape[0] != 0:\n",
    "        tmp['dist'] = tmp.apply(lambda row: haversine(row['lat_x'],row['lon_x'],row['lat_y'],row['lon_y']), axis=1)\n",
    "        dist = pd.concat([dist, tmp[['time','dist']]])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "dist.index = range(len(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's combine this into a single function that takes a given route and spits out the above dataframe of distances for that route\n",
    "\n",
    "The dataframe has a list of distances between successive trips for that route.\n",
    "\n",
    "This presumes that you are using the cleaned nbdata dataframe from above (which had all the precleaning done and takes ~10 minutes to run each time one restarts the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All documentation for this function can be found in the exploration I did above for route 30 specifically\n",
    "def compute_dists_for_route(route_num):\n",
    "    route_dat = nbdata[(nbdata.route == route_num)]\n",
    "    vehicles_for_route = pd.unique(route_dat.vehicle.ravel())\n",
    "    trips_in_order_for_route = np.sort(pd.unique(route_dat.trip.ravel()))\n",
    "    \n",
    "    coords_dict = {}\n",
    "    for i in range(len(trips_in_order_for_route)):\n",
    "        my_key = \"trip_\"+str(i)\n",
    "        if my_key not in coords_dict:\n",
    "            coords_dict[my_key] = 0\n",
    "\n",
    "    for i in range(len(trips_in_order_for_route)):\n",
    "        trip_temp = 'trip_'+str(i)\n",
    "        tmp_vehicles = pd.unique(route_dat[(route_dat.trip == trips_in_order_for_route[i])].vehicle.ravel())\n",
    "        coords_dict[trip_temp] = route_dat[(route_dat.trip == trips_in_order_for_route[i]) & (route_dat.vehicle == tmp_vehicles[0])][['lat','lon','time']]\n",
    "        coords_dict[trip_temp].drop_duplicates(subset='time', inplace=True)\n",
    "        coords_dict[trip_temp].index = coords_dict[trip_temp].time\n",
    "        \n",
    "    dist_tmp = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(trips_in_order_for_route)-1):\n",
    "        trip_now = 'trip_'+str(i)\n",
    "        trip_next = 'trip_'+str(i+1)\n",
    "        #print 'Merging {trip1} and {trip2}'.format(trip1=trip_now,trip2=trip_next)\n",
    "        tmp = pd.merge(left=coords_dict[trip_now],right=coords_dict[trip_next],on='time')\n",
    "        if tmp.shape[0] != 0:\n",
    "            tmp['dist'] = tmp.apply(lambda row: haversine(row['lat_x'],row['lon_x'],row['lat_y'],row['lon_y']), axis=1)\n",
    "            dist_tmp = pd.concat([dist_tmp, tmp[['time','dist']]])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    dist_tmp.index = range(len(dist_tmp))\n",
    "    \n",
    "    return dist_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of all routes available in the Muni system, so we can just choose from this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dict of these dataframes for **each** route in the list_of_muni_routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data from Google Maps API\n",
    "\n",
    "From there get stop ID of starting bus, from there get bus data from NextBus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('google_maps_api/second_dirs.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "#pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "route_name = str(data['routes'][0]['legs'][0]['steps'][0]['transit_details']['line']['short_name'])\n",
    "departure_stop = str(data['routes'][0]['legs'][0]['steps'][0]['transit_details']['departure_stop']['name'])\n",
    "departure_lat = float(data['routes'][0]['legs'][0]['steps'][0]['transit_details']['departure_stop']['location']['lat'])\n",
    "departure_lon = float(data['routes'][0]['legs'][0]['steps'][0]['transit_details']['departure_stop']['location']['lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "26th St & De Haro St\n",
      "37.75086\n",
      "-122.40015\n"
     ]
    }
   ],
   "source": [
    "print route_name\n",
    "print departure_stop\n",
    "print departure_lat\n",
    "print departure_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_get_route_config='http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&a=sf-muni&r='+str(route_name)\n",
    "route_config = pq(urlopen(url_get_route_config).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match at 26th St & De Haro St with stop id: 13516\n",
      "Coordinates of stop: (37.75086,-122.40015)\n"
     ]
    }
   ],
   "source": [
    "for bus_stop_obj in route_config('stop'):\n",
    "    bus_stop = pq(bus_stop_obj)\n",
    "    if bus_stop.attr('lat') is not None:\n",
    "        stop_name = str(bus_stop.attr('title'))\n",
    "        stop_lat = round(float(bus_stop.attr('lat')),5)\n",
    "        stop_lon = round(float(bus_stop.attr('lon')),5)\n",
    "        if stop_name == departure_stop and stop_lat == departure_lat and stop_lon == departure_lon:\n",
    "            stop_id = str(bus_stop.attr('stopId'))\n",
    "            print 'Match at '+stop_name+' with stop id: '+stop_id\n",
    "            print 'Coordinates of stop: ('+str(stop_lat)+','+str(stop_lon)+')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_get_stop_info='http://webservices.nextbus.com/service/publicXMLFeed?command=predictions&a=sf-muni&stopId='+stop_id\n",
    "stop_config = pq(urlopen(url_get_stop_info).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found correct bus route 19, trip ID = None\n"
     ]
    }
   ],
   "source": [
    "for next_bus_obj in stop_config('predictions'):\n",
    "    if str(pq(next_bus_obj).attr('routeTag')) == route_name:\n",
    "        for upcoming_trips in pq(next_bus_obj)\n",
    "        trip_id = pq(next_bus_obj).attr('tripTag')\n",
    "        print 'Found correct bus route '+str(pq(next_bus_obj).attr('routeTag'))+', trip ID = '+ str(trip_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head nextbus_one_day_sf_muni_dump.csv > tmp_dump.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('tmp_dump.txt') as my_file:\n",
    "    data = my_file.readlines()\n",
    "my_file.close()\n",
    "\n",
    "for i, line in enumerate(data,0):\n",
    "    # get rid of whitespaces, parentheses in coordinates, replace comma in coordinates with '|' so it splits,\n",
    "    # get rid of newlines, split on '|'\n",
    "    data[i] = line.replace(',','|').replace(' ','').replace('(','').replace(')','').replace('\\n','').split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vehiclid', 'receivedtimestamp', 'gpstimestamp', 'gpsfix', 'gpsspeed', 'gpsheading', 'route', 'trip']\n",
      "2016-01-1400:00:00.099-08\n"
     ]
    }
   ],
   "source": [
    "print data[0]\n",
    "print data[3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build distance distributions (nightly), save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate database of pairs\n",
    "With distance quantiles built in from previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
