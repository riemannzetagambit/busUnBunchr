{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "# all purpose\n",
    "import datetime, geoplotlib, re\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# for talking to SQL databases\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "# json and XML parsing\n",
    "import json\n",
    "from pprint import pprint\n",
    "from urllib2 import urlopen\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "# for making maps\n",
    "import geoplotlib\n",
    "from geoplotlib.utils import BoundingBox\n",
    "from IPython.display import Image\n",
    "\n",
    "# all purpose data analysis and plotting\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define this function for computing distances in meters from (lat,lon) coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will need this function to compute the distance between two (lat,lon) points, in meters\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    meters = 6367 * c * 1000\n",
    "    return meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from SQL database (necessary only to load Muni routes and estlabish connection to database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to connect to the PostgresSQL database that I am reading the NextBus Muni data into, which is called 'sf_muni_arrivals' in our case.\n",
    "\n",
    "**This cell must be run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbname = 'sf_muni_arrivals'\n",
    "username = 'dstone'\n",
    "table = 'nextbus_write_2016_01_15'\n",
    "\n",
    "# Open up an engine, that we will use to create the database if it doesn't exist\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "    \n",
    "# If I want to filter the data first:\n",
    "# connect:\n",
    "db_con = None\n",
    "db_con = psycopg2.connect(database = dbname, user = username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "These commands load the entire database into a pandas dataframe. I only used this to grab the list of Muni routes. It is not necessary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the table name is 'nextbus':\n",
    "# only run this code if the list_of_muni_routes needs to be reestablished\n",
    "# sql_query = \"\"\"\n",
    "# SELECT * FROM {table};\n",
    "# \"\"\".format(table=table)\n",
    "# nbdata = pd.read_sql_query(sql_query,db_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# routeslist = pd.unique(nbdata['route'].ravel())\n",
    "# list_of_muni_routes = pd.DataFrame(data=routeslist, index = range(len(routeslist)), columns=['route'])\n",
    "\n",
    "# # Clean up a bit\n",
    "# list_of_muni_routes = list_of_muni_routes[(list_of_muni_routes.route.isnull() == False) & (list_of_muni_routes.route != 'Inspectors') & (list_of_muni_routes.route != 'Training')]\n",
    "# list_of_muni_routes = list_of_muni_routes[list_of_muni_routes.route != '']\n",
    "# np.save('list_of_muni_routes',np.asarray(list_of_muni_routes).ravel())\n",
    "list_of_muni_routes = np.load('list_of_muni_routes.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building algorithm to construct database entries with predictions times as bunching qualifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with route 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get last stops of inbound and outbound buses for this route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "route_name = 10\n",
    "url_get_route_config='http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&a=sf-muni&r='+str(route_name)\n",
    "route_config = pq(urlopen(url_get_route_config).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found outbound\n",
      "Found inbound\n"
     ]
    }
   ],
   "source": [
    "for direction in pq(route_config('direction')):\n",
    "    dirIO = pq(direction).attr('tag')\n",
    "    stop_tag = pq(direction[-1]).attr('tag')\n",
    "    if 'I' in str(dirIO):\n",
    "        print 'Found inbound'\n",
    "        stop_tag_inbound = stop_tag\n",
    "    if 'O' in str(dirIO):\n",
    "        print 'Found outbound'\n",
    "        stop_tag_outbound = stop_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_get_predictions_inbound='http://webservices.nextbus.com/service/publicXMLFeed?command=predictions&a=sf-muni&s='+str(stop_tag_inbound)+'&r='+str(route_name)\n",
    "predictions_I = pq(urlopen(url_get_predictions_inbound).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_I = pd.DataFrame()\n",
    "indexer=0\n",
    "# Deal with lack of pairs later, but throw that as an error and don't display bunching\n",
    "for i in range(len(predictions_I('prediction'))-1):\n",
    "    if pq(predictions_I('prediction')[i]).attr.affectedByLayover is None or pq(predictions_I('prediction')[i+1]).attr.affectedByLayover is None: \n",
    "        prediction1 = pq(predictions_I('prediction')[i])\n",
    "        prediction2 = pq(predictions_I('prediction')[i+1])\n",
    "        df_tmp = pd.DataFrame({'vehicle1': prediction1.attr.vehicle, \\\n",
    "                            'vehicle2': prediction2.attr.vehicle, \\\n",
    "                            'pred1': prediction1.attr.minutes, \\\n",
    "                            'pred2': prediction2.attr.minutes}, index=[indexer])\n",
    "        df_I = df_I.append(df_tmp)\n",
    "        indexer += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_get_predictions_outbound='http://webservices.nextbus.com/service/publicXMLFeed?command=predictions&a=sf-muni&s='+str(stop_tag_outbound)+'&r='+str(route_name)\n",
    "predictions_O = pq(urlopen(url_get_predictions_outbound).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_O = pd.DataFrame()\n",
    "indexer=0\n",
    "# Deal with lack of pairs later, but throw that as an error and don't display bunching\n",
    "for i in range(len(predictions_O('prediction'))-1):\n",
    "    if pq(predictions('prediction')[i]).attr.affectedByLayover is None or pq(predictions_O('prediction')[i+1]).attr.affectedByLayover is None: \n",
    "        prediction1 = pq(predictions_O('prediction')[i])\n",
    "        prediction2 = pq(predictions_O('prediction')[i+1])\n",
    "        df_tmp = pd.DataFrame({'vehicle1': prediction1.attr.vehicle, \\\n",
    "                            'vehicle2': prediction2.attr.vehicle, \\\n",
    "                            'pred1': prediction1.attr.minutes, \\\n",
    "                            'pred2': prediction2.attr.minutes}, index=[indexer])\n",
    "        df_O = df_O.append(df_tmp)\n",
    "        indexer += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to realtime predictions and match the vehicle numbers (vehicles should have a unique ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_get_realtime_posits='http://webservices.nextbus.com/service/publicXMLFeed?command=vehicleLocations&a=sf-muni&t=0&r='+str(route_name)\n",
    "realtime_posits = pq(urlopen(url_get_realtime_posits).read())\n",
    "1453877206275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_total = pd.DataFrame()\n",
    "for df_tmp in [df_I, df_O]: \n",
    "    time_stamp = datetime.datetime.utcfromtimestamp(int(pq(pq(realtime_posits('vehicle')[-1]).siblings()[-1]).attr('time'))/1000)\n",
    "    # for each pair in df_I, find the match in the realtime_posits\n",
    "    df1 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame()\n",
    "    for i in range(df_tmp.shape[0]):\n",
    "        for vehicle in realtime_posits('vehicle'):\n",
    "            v = pq(vehicle)\n",
    "            if v.attr.id == df_tmp.loc[i]['vehicle1']:\n",
    "                df1 = pd.DataFrame({'ind':i, 'time': time_stamp,'lat_x': float(v.attr.lat), 'lon_x': float(v.attr.lon), 'speed_x': float(v.attr.speedKmHr), 'route_x': str(v.attr.routeTag), 'pred_x': df_tmp.loc[i]['pred1']},index=[0])\n",
    "                #df1 = df1.append(df1_tmp)\n",
    "            elif v.attr.id == df_tmp.loc[i]['vehicle2']:\n",
    "                df2 = pd.DataFrame({'ind':i, 'lat_y': float(v.attr.lat), 'lon_y': float(v.attr.lon), 'speed_y': float(v.attr.speedKmHr), 'pred_y': df_tmp.loc[i]['pred2']},index=[0])\n",
    "                #df2 = df2.append(df2_tmp)\n",
    "        if df1.empty or df2.empty:\n",
    "            continue\n",
    "        else:\n",
    "            df_tmp1 = pd.merge(left=df1, right=df2)\n",
    "            df_total = df_total.append(df_tmp1)\n",
    "\n",
    "# some cleaning\n",
    "df_total.drop('ind', inplace=True, axis=1)\n",
    "df_total.index = np.arange(df_total.shape[0])\n",
    "df_total['dist'] = df_total.apply(lambda row: haversine(row['lat_x'],row['lon_x'],row['lat_y'],row['lon_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_total['dist'] = df_total.apply(lambda row: haversine(row['lat_x'],row['lon_x'],row['lat_y'],row['lon_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_x</th>\n",
       "      <th>lon_x</th>\n",
       "      <th>pred_x</th>\n",
       "      <th>route_x</th>\n",
       "      <th>speed_x</th>\n",
       "      <th>time</th>\n",
       "      <th>lat_y</th>\n",
       "      <th>lon_y</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>speed_y</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.79248</td>\n",
       "      <td>-122.43439</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-01-27 01:49:22</td>\n",
       "      <td>37.79278</td>\n",
       "      <td>-122.40137</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>3669.394770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.79278</td>\n",
       "      <td>-122.40137</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-27 01:49:22</td>\n",
       "      <td>37.77750</td>\n",
       "      <td>-122.39444</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>1191.949541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.77750</td>\n",
       "      <td>-122.39444</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-01-27 01:49:22</td>\n",
       "      <td>37.75455</td>\n",
       "      <td>-122.40207</td>\n",
       "      <td>53</td>\n",
       "      <td>25</td>\n",
       "      <td>1608.146356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.75455</td>\n",
       "      <td>-122.40207</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>2016-01-27 01:49:22</td>\n",
       "      <td>37.75305</td>\n",
       "      <td>-122.40611</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>457.745690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.75105</td>\n",
       "      <td>-122.39845</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-01-27 01:49:22</td>\n",
       "      <td>37.78860</td>\n",
       "      <td>-122.40049</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2247.300688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.78860</td>\n",
       "      <td>-122.40049</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-27 01:49:22</td>\n",
       "      <td>37.79866</td>\n",
       "      <td>-122.40140</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>607.501916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37.79866</td>\n",
       "      <td>-122.40140</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-27 01:49:22</td>\n",
       "      <td>37.79243</td>\n",
       "      <td>-122.43514</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3767.686087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lat_x      lon_x pred_x route_x  speed_x                time     lat_y  \\\n",
       "0  37.79248 -122.43439      0      10        7 2016-01-27 01:49:22  37.79278   \n",
       "1  37.79278 -122.40137     22      10        9 2016-01-27 01:49:22  37.77750   \n",
       "2  37.77750 -122.39444     33      10       18 2016-01-27 01:49:22  37.75455   \n",
       "3  37.75455 -122.40207     53      10       25 2016-01-27 01:49:22  37.75305   \n",
       "4  37.75105 -122.39845      5      10       12 2016-01-27 01:49:22  37.78860   \n",
       "5  37.78860 -122.40049     33      10        0 2016-01-27 01:49:22  37.79866   \n",
       "6  37.79866 -122.40140     44      10        0 2016-01-27 01:49:22  37.79243   \n",
       "\n",
       "       lon_y pred_y  speed_y         dist  \n",
       "0 -122.40137     22        9  3669.394770  \n",
       "1 -122.39444     33       18  1191.949541  \n",
       "2 -122.40207     53       25  1608.146356  \n",
       "3 -122.40611     70        0   457.745690  \n",
       "4 -122.40049     33        0  2247.300688  \n",
       "5 -122.40140     44        0   607.501916  \n",
       "6 -122.43514     65        0  3767.686087  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the 'enter_pairs_for_route_into_database(route)'\n",
    "Now make one big function that does this for each route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def temp_func(specified_route):\n",
    "    # Get last stops of inbound and outbound buses for this route\n",
    "    url_get_route_config='http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&a=sf-muni&r='+str(specified_route)\n",
    "    route_config = pq(urlopen(url_get_route_config).read())\n",
    "    for direction in pq(route_config('direction')):\n",
    "        dirIO = pq(direction).attr('tag')\n",
    "        stop_tag = pq(direction[-1]).attr('tag')\n",
    "        print 'stop_tag = '+str(stop_tag)\n",
    "        if 'I' in str(dirIO):\n",
    "            stop_tag_inbound = stop_tag\n",
    "        if 'O' in str(dirIO):\n",
    "            stop_tag_outbound = stop_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['29', '21', '28'], dtype=object)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_muni_routes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def enter_pairs_for_route_into_database(specified_route, specified_engine, specified_table):\n",
    "    # Get last stops of inbound and outbound buses for this route\n",
    "    url_get_route_config='http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&a=sf-muni&r='+str(specified_route)\n",
    "    route_config = pq(urlopen(url_get_route_config).read())\n",
    "    print 'route: '+str(specified_route)\n",
    "    print url_get_route_config\n",
    "    for direction in pq(route_config('direction')):\n",
    "        dirIO = pq(direction).attr('tag')\n",
    "        stop_tag = pq(direction[-1]).attr('tag')\n",
    "        print 'stop_tag: '+str(stop_tag)\n",
    "        if 'I' in str(dirIO):\n",
    "            stop_tag_inbound = stop_tag\n",
    "            print 'stop_tag_inbound = '+str(stop_tag_inbound)\n",
    "        if 'O' in str(dirIO):\n",
    "            stop_tag_outbound = stop_tag\n",
    "            print 'stop_tag_outbound = '+str(stop_tag_outbound)\n",
    "\n",
    "    # Get predictions in pairs\n",
    "    # First inbound\n",
    "    try:\n",
    "        stop_tag_inbound\n",
    "    except:\n",
    "        stop_tag_inbound = None\n",
    "        df_I = pd.DataFrame()\n",
    "    if stop_tag_inbound is not None:\n",
    "        print 'stop_tag_inbound here'\n",
    "        url_get_predictions_inbound='http://webservices.nextbus.com/service/publicXMLFeed?command=predictions&a=sf-muni&s='+str(stop_tag_inbound)+'&r='+str(specified_route)\n",
    "        predictions_I = pq(urlopen(url_get_predictions_inbound).read())\n",
    "        df_I = pd.DataFrame()\n",
    "        indexer=0\n",
    "        # Deal with lack of pairs later, but throw that as an error and don't display bunching\n",
    "        for i in range(len(predictions_I('prediction'))-1):\n",
    "            if pq(predictions_I('prediction')[i]).attr.affectedByLayover is None or pq(predictions_I('prediction')[i+1]).attr.affectedByLayover is None: \n",
    "                prediction1 = pq(predictions_I('prediction')[i])\n",
    "                prediction2 = pq(predictions_I('prediction')[i+1])\n",
    "                #print 'prediction1: '+str(prediction1)\n",
    "                #print 'prediction2: '+str(prediction2)\n",
    "                df_tmp = pd.DataFrame({'vehicle1': prediction1.attr.vehicle, \\\n",
    "                                    'vehicle2': prediction2.attr.vehicle, \\\n",
    "                                    'pred1': prediction1.attr.minutes, \\\n",
    "                                    'pred2': prediction2.attr.minutes}, index=[indexer])\n",
    "                df_I = df_I.append(df_tmp)\n",
    "                indexer += 1\n",
    " \n",
    "    # Now outbound\n",
    "    try:\n",
    "        stop_tag_outbound\n",
    "    except:\n",
    "        stop_tag_outbound = None\n",
    "        df_O = pd.DataFrame()\n",
    "    if stop_tag_outbound is not None:\n",
    "        print 'stop_tag_outbound here'\n",
    "        url_get_predictions_outbound='http://webservices.nextbus.com/service/publicXMLFeed?command=predictions&a=sf-muni&s='+str(stop_tag_outbound)+'&r='+str(specified_route)\n",
    "        predictions_O = pq(urlopen(url_get_predictions_outbound).read())\n",
    "        df_O = pd.DataFrame()\n",
    "        indexer=0\n",
    "        # Deal with lack of pairs later, but throw that as an error and don't display bunching\n",
    "        for i in range(len(predictions_O('prediction'))-1):\n",
    "            if pq(predictions_O('prediction')[i]).attr.affectedByLayover is None or pq(predictions_O('prediction')[i+1]).attr.affectedByLayover is None: \n",
    "                prediction1 = pq(predictions_O('prediction')[i])\n",
    "                prediction2 = pq(predictions_O('prediction')[i+1])\n",
    "                df_tmp = pd.DataFrame({'vehicle1': prediction1.attr.vehicle, \\\n",
    "                                    'vehicle2': prediction2.attr.vehicle, \\\n",
    "                                    'pred1': prediction1.attr.minutes, \\\n",
    "                                    'pred2': prediction2.attr.minutes}, index=[indexer])\n",
    "                df_O = df_O.append(df_tmp)\n",
    "                indexer += 1\n",
    "                \n",
    "    if df_I.empty and df_O.empty:\n",
    "        print 'Not doing anything'\n",
    "        return\n",
    "    elif df_I.empty:\n",
    "        df_array = [df_O]\n",
    "    elif df_O.empty:\n",
    "        df_array = [df_I]\n",
    "    else:\n",
    "        df_array = [df_I, df_O]\n",
    "    # Now go to realtime predictions and match the vehicle numbers (vehicles should have a unique ID)\n",
    "    url_get_realtime_posits='http://webservices.nextbus.com/service/publicXMLFeed?command=vehicleLocations&a=sf-muni&t=0&r='+str(specified_route)\n",
    "    realtime_posits = pq(urlopen(url_get_realtime_posits).read())\n",
    "    df_total = pd.DataFrame()\n",
    "    for df_tmp in df_array: \n",
    "        time_stamp = datetime.datetime.utcfromtimestamp(int(pq(pq(realtime_posits('vehicle')[-1]).siblings()[-1]).attr('time'))/1000)\n",
    "        # for each pair in df_I, find the match in the realtime_posits\n",
    "        df1 = pd.DataFrame()\n",
    "        df2 = pd.DataFrame()\n",
    "        for i in range(df_tmp.shape[0]):\n",
    "            for vehicle in realtime_posits('vehicle'):\n",
    "                v = pq(vehicle)\n",
    "                if v.attr.id == df_tmp.loc[i]['vehicle1']:\n",
    "                    df1 = pd.DataFrame({'ind':i, 'time': time_stamp,'lat_x': float(v.attr.lat), 'lon_x': float(v.attr.lon), 'speed_x': float(v.attr.speedKmHr), 'route_x': str(v.attr.routeTag), 'pred_x': df_tmp.loc[i]['pred1']},index=[0])\n",
    "                    #df1 = df1.append(df1_tmp)\n",
    "                elif v.attr.id == df_tmp.loc[i]['vehicle2']:\n",
    "                    df2 = pd.DataFrame({'ind':i, 'lat_y': float(v.attr.lat), 'lon_y': float(v.attr.lon), 'speed_y': float(v.attr.speedKmHr), 'pred_y': df_tmp.loc[i]['pred2']},index=[0])\n",
    "                    #df2 = df2.append(df2_tmp)\n",
    "            if df1.empty or df2.empty:\n",
    "                continue\n",
    "            else:\n",
    "                df_tmp1 = pd.merge(left=df1, right=df2)\n",
    "                df_total = df_total.append(df_tmp1)\n",
    "\n",
    "    if not df_total.empty:\n",
    "        print 'yay!'\n",
    "        \n",
    "    # check to make sure we've actually found something\n",
    "    if df_total.empty:\n",
    "        # don't add anything this time around (remember, this just adds buses from this route for this specific call)\n",
    "        return\n",
    "    else:\n",
    "        # some cleaning\n",
    "        df_total.drop('ind', inplace=True, axis=1)\n",
    "        df_total.index = np.arange(df_total.shape[0])\n",
    "        # add distance after computing for this route\n",
    "        df_total['dist'] = df_total.apply(lambda row: haversine(row['lat_x'],row['lon_x'],row['lat_y'],row['lon_y']), axis=1)\n",
    "\n",
    "        # Now right this beast to a SQL database specified by input\n",
    "        df_total.to_sql(specified_table, specified_engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not doing anything\n"
     ]
    }
   ],
   "source": [
    "enter_pairs_for_route_into_database('30', engine, 'nextbus_realtime_with_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not doing anything\n"
     ]
    }
   ],
   "source": [
    "enter_pairs_for_route_into_database('21', engine, 'nextbus_realtime_with_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route: 29\n",
      "http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&a=sf-muni&r=29\n",
      "stop_tag: 34648\n",
      "stop_tag_outbound = 34648\n",
      "stop_tag: 33706\n",
      "stop_tag_inbound = 33706\n",
      "stop_tag_inbound here\n",
      "stop_tag_outbound here\n",
      "yay!\n",
      "route: 21\n",
      "http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&a=sf-muni&r=21\n",
      "stop_tag: 37499\n",
      "stop_tag_outbound = 37499\n",
      "stop_tag: 37832\n",
      "stop_tag_inbound = 37832\n",
      "stop_tag_inbound here\n",
      "stop_tag_outbound here\n",
      "yay!\n",
      "route: 28\n",
      "http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&a=sf-muni&r=28\n",
      "stop_tag: 34341\n",
      "stop_tag_outbound = 34341\n",
      "stop_tag: 7799\n",
      "stop_tag_inbound = 7799\n",
      "stop_tag_inbound here\n",
      "stop_tag_outbound here\n",
      "yay!\n"
     ]
    }
   ],
   "source": [
    "for route in list_of_muni_routes[:3]:\n",
    "    enter_pairs_for_route_into_database(route, engine, 'testing_loop')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
